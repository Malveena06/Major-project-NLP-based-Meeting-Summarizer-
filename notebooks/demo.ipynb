{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Video to Text & Summarization with OpenAI's Whisper and GPT-3\n",
    "\n",
    "This notebook implements a sequential data processing pipeline for creating text summaries from video links.\n",
    "\n",
    "The processing steps are:\n",
    "\n",
    "1. Download video(s) using _yt-dlp_.\n",
    "2. Extract audio using _FFMPEG_.\n",
    "3. Transcribe the audio to text, using OpenAI's _Whisper_.\n",
    "4. Creating summary of the text, using OpenAI's _GPT-3_.\n",
    "\n",
    "The output of each is saved to a file inside the respective feature directory inside the DATA directory (see .env config file)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "cwd = Path(os.getcwd())\n",
    "src = cwd.parent / 'src'\n",
    "sys.path.append(src)\n",
    "\n",
    "from src.video2audio.ffmpegaudioextraction import FFmpegAudioExtraction\n",
    "from src.audio2text.whisperwrapper import WhisperWrapper\n",
    "from src.text2summary.gpt3wrapper import GPT3Wrapper\n",
    "from src.util.fs import LocalFSUtil\n",
    "\n",
    "rel_path = '../'\n",
    "dotenv_path = Path(rel_path + '.env')\n",
    "if not dotenv_path.exists():\n",
    "    raise Exception(\"Config file not found: \", dotenv_path)\n",
    "else:\n",
    "    load_dotenv(dotenv_path=dotenv_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Configuration ***\n",
      "Whisper model: base.en\n",
      "spaCy   model: en_core_web_sm\n",
      "GPT-3   model: text-davinci-003\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "DATA_DIR = os.getenv('DATA_DIR')\n",
    "DATA_DIR_VIDEO_FEATURES = os.getenv('DATA_DIR_VIDEO_FEATURES')\n",
    "DATA_DIR_AUDIO_FEATURES = os.getenv('DATA_DIR_AUDIO_FEATURES')\n",
    "DATA_DIR_TEXT_FEATURES = os.getenv('DATA_DIR_TEXT_FEATURES')\n",
    "DATA_DIR_TEXT_SUMMARIES = os.getenv('DATA_DIR_TEXT_SUMMARIES')\n",
    "\n",
    "# If paths are not absolute, adjust them to be in the parent directory\n",
    "fsutil = LocalFSUtil()\n",
    "if not fsutil.is_absolute_path(DATA_DIR): DATA_DIR = fsutil.normalise_path(rel_path + DATA_DIR)\n",
    "if not fsutil.is_absolute_path(DATA_DIR_VIDEO_FEATURES): DATA_DIR_VIDEO_FEATURES = fsutil.normalise_path(rel_path + DATA_DIR_VIDEO_FEATURES)\n",
    "if not fsutil.is_absolute_path(DATA_DIR_AUDIO_FEATURES): DATA_DIR_AUDIO_FEATURES = fsutil.normalise_path(rel_path + DATA_DIR_AUDIO_FEATURES)\n",
    "if not fsutil.is_absolute_path(DATA_DIR_TEXT_FEATURES): DATA_DIR_TEXT_FEATURES = fsutil.normalise_path(rel_path + DATA_DIR_TEXT_FEATURES)\n",
    "if not fsutil.is_absolute_path(DATA_DIR_TEXT_SUMMARIES): DATA_DIR_TEXT_SUMMARIES = fsutil.normalise_path(rel_path + DATA_DIR_TEXT_SUMMARIES)\n",
    "\n",
    "for path in [DATA_DIR, DATA_DIR_VIDEO_FEATURES, DATA_DIR_AUDIO_FEATURES, DATA_DIR_TEXT_FEATURES, DATA_DIR_TEXT_SUMMARIES]:\n",
    "    if fsutil.ensure_path_exists(path):\n",
    "        print(f\"Created '{path}'\")\n",
    "\n",
    "WHISPER_DEFAULT_MODEL = os.getenv('WHISPER_DEFAULT_MODEL')\n",
    "SPACY_DEFAULT_MODEL = os.getenv('SPACY_DEFAULT_MODEL')\n",
    "GPT3_DEFAULT_MODEL = os.getenv('GPT3_DEFAULT_MODEL')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(\"*** Configuration ***\")\n",
    "print(\"Whisper model:\", WHISPER_DEFAULT_MODEL)\n",
    "print(\"spaCy   model:\", SPACY_DEFAULT_MODEL)\n",
    "print(\"GPT-3   model:\", GPT3_DEFAULT_MODEL)\n",
    "\n",
    "video_proxy = FFmpegAudioExtraction()\n",
    "whisper_proxy = WhisperWrapper(WHISPER_DEFAULT_MODEL)\n",
    "gpt3_proxy = GPT3Wrapper(GPT3_DEFAULT_MODEL, OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example we will transcribe JFK's famous speech to congress on space exploration from 1961."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=8ygoE2YiHCs\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded (1/1): JFK's Famous Speech to Congress on Space Exploration (1961) ｜ The Kennedy Center [8ygoE2YiHCs].webm\n"
     ]
    }
   ],
   "source": [
    "# Download videos\n",
    "from util.videodownloader import YouTubeDownloader\n",
    "downloader = YouTubeDownloader()\n",
    "video_files = []\n",
    "if video_urls:\n",
    "    for video_nr, video_url in enumerate(video_urls, start=1):\n",
    "        try:\n",
    "            video_file = downloader.download(video_url, DATA_DIR_VIDEO_FEATURES)\n",
    "            video_files.append(video_file)\n",
    "            print(f\"Downloaded ({video_nr}/{len(video_urls)}): {os.path.basename(video_file)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download: {video_url} due to '{str(e)}'\")\n",
    "else:\n",
    "    # Use previously downloaded videos\n",
    "    video_files = fsutil.list_files(DATA_DIR_VIDEO_FEATURES, ignore_empty=True)\n",
    "    video_files = filter(fsutil.delete_file_if_empty, video_files)\n",
    "\n",
    "    for video_nr, video_file in enumerate(video_files, start=1):\n",
    "        print(f\"Found video ({video_nr}/{len(video_files)}): {os.path.basename(video_file)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/1 (100%) *** JFK's Famous Speech to Congress on Space Exploration (1961) ｜ The Kennedy Center [8ygoE2YiHCs].webm \n",
      "-> Audio has already been extracted.\n",
      "-> Text has already been transcribed.\n",
      "-> Creating summary text (1 KB) ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process files\n",
    "for file_nr, video_file in enumerate(video_files, start=1):\n",
    "\n",
    "    # progress indicator\n",
    "    progress_str = str(int(100 * file_nr / len(video_files)))\n",
    "    progress_str = f\"{file_nr}/{len(video_files)} ({progress_str}%) *** {os.path.basename(video_file)} \"\n",
    "    progress_str = f\"Processing file {progress_str}\"\n",
    "    print(progress_str)\n",
    "\n",
    "    # prepare filenames\n",
    "    audio_file = fsutil.source_to_target(video_file, DATA_DIR_AUDIO_FEATURES, '.mp3')\n",
    "    text_file = fsutil.source_to_target(audio_file, DATA_DIR_TEXT_FEATURES, '.txt')\n",
    "    summary_file = fsutil.source_to_target(text_file, DATA_DIR_TEXT_SUMMARIES, '-summary.txt')\n",
    "\n",
    "    fsutil.delete_file_if_empty(audio_file)\n",
    "    fsutil.delete_file_if_empty(text_file)\n",
    "    fsutil.delete_file_if_empty(summary_file)\n",
    "\n",
    "    if not fsutil.exists(audio_file):\n",
    "        print(f\"-> Extracting audio from video ({fsutil.get_size_str(video_file)}) ...\")\n",
    "        video_proxy.convert_to_audio(video_file, audio_file)\n",
    "    else:\n",
    "        print(\"-> Audio has already been extracted.\")\n",
    "\n",
    "    if not fsutil.exists(text_file):\n",
    "        print(f\"-> Transcribing audio to text ({fsutil.get_size_str(audio_file)}) ...\")\n",
    "        print(whisper_proxy)\n",
    "        whisper_proxy.transcribe_to_file(audio_file, text_file, overwrite=True)\n",
    "    else:\n",
    "        print(\"-> Text has already been transcribed.\")\n",
    "\n",
    "    if not fsutil.exists(summary_file):\n",
    "        print(f\"-> Creating summary text ({fsutil.get_size_str(text_file)}) ...\")\n",
    "        text = fsutil.load_text(text_file)\n",
    "        text_summary = gpt3_proxy.summarise_to_file(text_file, summary_file)\n",
    "    else:\n",
    "        print(\"-> Summary has already been created.\")\n",
    "\n",
    "    print()\n",
    "\n",
    "# Select a video to process\n",
    "# List packages in dir"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
